- date: 3 Oct 2025
  speaker: Xinle Tian (University of Bath)
  url: https://xinlet.github.io/
  zoom: 1
  title: Large multi-response linear regression estimation based on low-rank pre-smoothing
  abstract: Pre-smoothing is a technique aimed at increasing the signal-to-noise ratio in data to improve subsequent estimation and model selection in regression problems. Motivated by the many scientific applications in which multi-response regression problems arise, particularly when the number of responses is large, we propose here to extend pre-smoothing methods to the multiple outcome setting. Specifically, we introduce and study a simple technique for pre-smoothing based on low-rank approximation. We establish theoretical results on the performance of the proposed methodology, which show that in the large-response setting, the proposed technique outperforms ordinary least squares estimation with the mean squared error criterion, whilst being computationally more efficient than alternative approaches such as reduced rank regression. We quantify our estimator's benefit empirically in a number of simulated experiments. We also demonstrate our proposed low-rank pre-smoothing technique on real data arising from the environmental and biological sciences.

- date: 3 Oct 2025
  speaker: James Martin (University of Bath)
  url: https://uk.linkedin.com/in/james-martin-07a1b2230
  zoom: 1
  title: 'Percolation and localisation: Sub-leading eigenvalues of the nonbacktracking matrix'
  abstract: 'Network percolation is a well-studied random process that investigates the long-range connectivity properties of a network. The spectrum of the nonbacktracking matrix associated to a network is known to contain fundamental information regarding percolation properties. Indeed, the inverse of its leading eigenvalue is often used as an estimate for the percolation threshold. However, for many networks where nonbacktracking centrality is localised on a few nodes, such as networks with a core-periphery structure, this spectral approach badly underestimates the threshold. We study networks that exhibit this localisation effect by looking beyond the leading eigenvalue and searching deeper into the spectrum of the nonbacktracking matrix. We identify that, when localisation is present, the threshold often more closely aligns with the inverse of one of the sub-leading real eigenvalues: the largest real eigenvalue with a "delocalised" corresponding eigenvector. We discuss some intuition behind this observation and present experimental results on large scale real-world networks that showcase the usefulness of our approach.'

- date: 10 Oct 2025
  speaker: Caitlin O'Hara (University of Bath)
  url: https://researchportal.bath.ac.uk/en/persons/caitlin-ohara
  zoom: 1
  title: Physics Enhanced Deep Surrogates for Solving Partial Differential Equations
  abstract: "I'll present Physics Enhanced Deep Surrogate (PEDS) models, a hybrid approach that combines neural networks with traditional PDE solvers to efficiently solve diffusion problems. The method addresses the computational challenge of needing thousands of PDE evaluations for material design optimisation by maintaining physical accuracy whilst achieving significant speedup over conventional numerical methods."

- date: 10 Oct 2025
  speaker: Viraj Patel (University of Bath)
  url: https://cdt-art-ai.ac.uk/students/viraj-patel/
  zoom: 1
  title: Intraventricular flow reconstruction and graph-based representations
  abstract: Ultrasound imaging is a widely used technique for assessing cardiovascular health and diagnosing various heart conditions. There is good data to suggest that blood flow is sensitive to disease and may provide valuable insights into the efficiency of cardiac pumping and overall circulation. As a result, the blood velocity field within the heart chambers may be a critical parameter in evaluating cardiac function, so accurate measurements could potentially lead to new diagnostic or prognostic metrics for heart failure. However, accurately measuring blood velocity using ultrasound remains challenging due to inherent limitations like noise and the complex nature of blood flow dynamics, in conjunction with flaws in current velocimetry techniques. The left ventricle is particularly important as its primary function is to provide sufficient cardiac output to maintain blood flow to other organ systems in the body. As the left ventricle fills up with blood, the difference between the inlet width and the ventricle width causes a vortex to form, called the left ventricular vortex (LVV). The literature suggests that the vortex formation time and the geometry of the LVV are connected to heart failure and diastolic function. The deviations of expected dynamics of the LVV has been attributed to structural and functional deformities in the heart walls and myocardium (left ventricular muscle). Much of the work in this field have relied on simulations and experiments with models of the left ventricle, while this work has used data collected from a real heart under controlled conditions. Thus far, I have developed an ellipse-fit method to quantify the size and orientation of the LVV in real-time. I aim to extend this work to find unique representations of intraventricular flow fields that can discern different flow conditions. In this talk, I will present an idea that uses Gabriel graphs to form a latent representation of flow fields in the heart.

- date: 17 Oct 2025
  speaker: Thomas Coxon (Loughborough University)
  url: https://github.com/tttc3
  zoom: 1
  title: "From 1/√n to 1/n: Accelerating SDE Simulation with Cubature Formulae (part 1)"
  abstract: Monte Carlo sampling is the standard approach for estimating properties of solutions to stochastic differential equations (SDEs), but its error decays only as 1/√n, requiring huge sample sizes. Lyons and Victoir (2004) proposed replacing independently sampled Brownian driving paths with "cubature formulae", deterministic weighted sets of paths that match Brownian "signature moments" up to some degree D. They prove that cubature formulae exist for arbitrary D, but explicit constructions are difficult and have only reached D=7, too small for practical use. We present an algorithm that efficiently and automatically constructs cubature formulae of arbitrary degree, reproducing D=7 in seconds and reaching D=17 within hours on modest hardware. In simulations across multiple SDEs, our cubature formulae achieve an error roughly of order 1/n, orders of magnitude smaller than Monte Carlo with the same number of paths.

- date: 17 Oct 2025
  speaker: Peter Koepernik (University of Oxford)
  url: https://peter.koepernik.net/
  zoom: 1
  title: "From 1/√n to 1/n: Accelerating SDE Simulation with Cubature Formulae (part 2)"
  abstract: Monte Carlo sampling is the standard approach for estimating properties of solutions to stochastic differential equations (SDEs), but its error decays only as 1/√n, requiring huge sample sizes. Lyons and Victoir (2004) proposed replacing independently sampled Brownian driving paths with "cubature formulae", deterministic weighted sets of paths that match Brownian "signature moments" up to some degree D. They prove that cubature formulae exist for arbitrary D, but explicit constructions are difficult and have only reached D=7, too small for practical use. We present an algorithm that efficiently and automatically constructs cubature formulae of arbitrary degree, reproducing D=7 in seconds and reaching D=17 within hours on modest hardware. In simulations across multiple SDEs, our cubature formulae achieve an error roughly of order 1/n, orders of magnitude smaller than Monte Carlo with the same number of paths.

- date: 24 Oct 2025
  speaker: Cangxiong Chen (University of Bath)
  url: https://cangxiongchen.github.io/
  zoom: 1
  title: Solving Life-Cycle Models Using Neural Networks
  abstract: In this talk, I will present how we can develop solutions to life cycle models in macroeconomics using neural networks. This is based on joint work from Avi Mayorcas (Bath), Sigmund Ellingsrud, Fabian Harang, and Alfonso Irarrazabal (BI Oslo), which provides a stochastic analysis of an overlapping-generations model under incomplete markets. My focus will be on how neural networks can efficiently approximate the solution to the optimal control problem from the model, yielding a consumption policy that is flexible, generative and scalable.

- date: 24 Oct 2025
  speaker: Ahmed Rashwan (University of Bath)
  url: https://samba.ac.uk/student/ahmed-rashwan/
  zoom: 1
  title: Enforcing convex constraints in Graph Neural Networks
  abstract: Many machine learning tasks require model outputs to satisfy specific convex constraints. Enforcing these constraints is especially difficult in Graph Neural Networks, as graph-structured data results in outputs of varying sizes. We introduce a simple neural network architecture which guarantees constraint satisfaction. Our method leverages the Component-Averaged Dykstra (CAD) algorithm — a sparse, iterative scheme for computing convex projections. We establish a convergence result for CAD and present a GPU-accelerated implementation capable of efficiently processing large-scale data. Experiments across four classes of constrained optimisation problems demonstrate that our approach is significantly faster than traditional optimisation techniques.

- date: 31 Oct 2025
  speaker: Sam Power (University of Bristol)
  url: https://sites.google.com/view/sp-monte-carlo/ 
  zoom: 1
  title: Gradient Flow Methods for Statistical Computation - Trends and Trajectories
  abstract: "When conducting statistical estimation and inference, it is relatively commonplace that the dominant computational burden takes the form of an optimisation task. This has long been recognised for tasks of parameter estimation, though there is an increasing recognition that other tasks of interest can be fruitfully interpreted as optimisation tasks over a space of probability measures, or even over some 'hybrid' space involving both parameters and measures.<br><br> In this talk, I will survey some trends in this area, focusing on how this high-level perspective finds use in both analysis of popular existing algorithms and synthesis of novel algorithms. I will also highlight opportunities for future contributions in this fast-growing area."

- date: 7 Nov 2025
  speaker: Robert Johnson (University of Bath)
  url: https://samba.ac.uk/student/robert-johnson/
  zoom: 1
  title: Mathematical Methods for Ptychography Imaging
  abstract: Ptychography is an inverse problem that aims to recover the modulus and phase of a complex-valued sample under illumination from its diffraction pattern. Recovery algorithms use an iterative approach to recover the phase and amplitude by looking at the difference between the diffraction pattern of the true sample and the diffraction pattern of the current best guess of the sample.<br><br> In this talk a new mathematical method for Ptychographic recovery using the L-BFGS optimization algorithm will be presented and compared to an existing recovery algorithm on synthetically generated data. The new method will later be extended for use in Spectral Ptychography, which is performing Ptychography at multiple illumination beam energies. 

- date: 7 Nov 2025
  speaker: Joanna Ni (University of Bath)
  url: https://samba.ac.uk/student/joanna-ni/
  zoom: 1
  title: Coarse-to-Fine Acceleration Framework for Probabilistic Shape Models
  abstract: Training probabilistic diffeomorphic shape models is computationally demanding due to repeated flow computations and the variance arising in stochastic optimisation. We propose a coarse-to-fine framework that first pre-trains the model on a much smaller set of control points and then refines it at higher resolution using the fitted parameters. The coarse model acts as a control variate for the fine level, yielding lower-variance gradient estimates and faster objective decay. This approach accelerates convergence and enhances computational efficiency while preserving modelling accuracy.

- date: 14 Nov 2025
  speaker: Zhengang Zhong (University of Warwick)
  url: https://zhengang-zhong.github.io/
  zoom: 1
  title: Learning and optimization in Infinite-Dimensional Spaces under Uncertainty
  abstract: Two related problems involving learning and optimization with infinite-dimensional structure are considered.<br><br> In the first part, Laplace Learning in the setting of functional data is studied. Laplace Learning is a graph-based method for semi-supervised learning, where partially labelled feature vectors are used to infer missing labels by minimizing a Dirichlet energy on the graph. Under suitable scaling of the graph connectivity, a continuum PDE limit can be obtained as the number of data points increases. However, the required connectivity condition imposes a dimension-dependent scaling that fails in infinite dimensions. This limitation is addressed by establishing meaningful limiting behavior when the data are generated by infinite-dimensional Gaussian measures.<br><br> In the second part, optimal actuator and control design is formulated as a multilevel optimization problem, where actuator performance is determined by the solution of a PDE-constrained optimal control problem. Because repeatedly solving this control problem is computationally expensive, neural network surrogate models are introduced to replace the lower level of the optimization hierarchy, enabling efficient gradient-based optimization and gradient-free consensus-based optimization methods to determine the optimal actuator design. Furthermore, by analyzing the optimality conditions of the control problem, the surrogate is enhanced through gradient-based training to improve performance when only limited training data are accessible. The effectiveness of the proposed surrogate models and optimization methods is demonstrated in actuator placement problems for heat equation and Burgers' equation.

- date: 21 Nov 2025
  speaker: Alain Zemkoho (University of Southampton)
  url: https://www.southampton.ac.uk/~abz1e14/
  zoom: 1
  title: Pessimistic bilevel optimization
  abstract: When the lower-level optimal solution set-valued mapping of a bilevel optimization problem is not single-valued, we are faced with an ill-posed problem, which gives rise to the optimistic and pessimistic bilevel optimization problems, as tractable algorithmic frameworks. However, solving the pessimistic bilevel optimization problem is far more challenging than the optimistic one; hence, the literature has mostly been dedicated to the latter class of the problem. In this talk, we will briefly discuss the main models and challenges associated to ill-posed bilevel programs, and subsequently, we will focus our attention on some practical techniques to compute solutions for pessimistic bilevel optimization problems. The main algorithmic approaches that we will explore are relaxation-type methods and their convergence analysis.

- date: 28 Nov 2025
  speaker: David Wörgötter (TU Wien)
  url: https://at.linkedin.com/in/david-w%C3%B6rg%C3%B6tter-b97a66204
  zoom: 1
  title: TBC
  abstract:

- date: 5 Dec 2025
  speaker: MMath students
  url:
  zoom: 1
  title: "Year-Long Projects"
  abstract:

- date: 12 Dec 2025
  speaker: Sean Holman (University of Manchester)
  url: https://research.manchester.ac.uk/en/persons/sean.holman
  zoom: 1
  title: TBC
  abstract: