- date: 5 Feb 2021
  speaker: Alberto Paganini (Leicester)
  url: https://www2.le.ac.uk/departments/mathematics/extranet/staff-material/staff-profiles/alberto-paganini
  teams: https://teams.microsoft.com/l/meetup-join/19%3ad8aa162230c14a67a10243ac2f75d98d%40thread.tacv2/1612172995109?context=%7b%22Tid%22%3a%22377e3d22-4ea1-422d-b0ad-8fcc89406b9e%22%2c%22Oid%22%3a%22ca31603c-bea1-49a9-9542-de84a57ad77c%22%7d
  title: Automated shape optimization with finite elements
  abstract: Shape optimization studies how to design a domain such that a shape function is minimized. Ubiquitous in industrial applications, shape optimization is often constrained to partial differential equations (PDEs). In such instances, deriving shape derivative formulas by hand and coupling domain updates with PDE-solvers can be challenging, if not discouraging. In this talk, we give a gentle introduction to shape optimization and illustrate how finite element techniques allow automating shape optimization and hence tackling challenging PDE-constrained problems with ease.

- date: 12 Feb 2021
  speaker: Ronald Morgan (Baylor University, US)
  inred: 'different time: 2:15 pm'
  url: https://www.baylor.edu/math/index.php?id=54013
  teams: https://teams.microsoft.com/l/meetup-join/19%3ad8aa162230c14a67a10243ac2f75d98d%40thread.tacv2/1612172995109?context=%7b%22Tid%22%3a%22377e3d22-4ea1-422d-b0ad-8fcc89406b9e%22%2c%22Oid%22%3a%22ca31603c-bea1-49a9-9542-de84a57ad77c%22%7d
  title: Solving Large Systems of Linear Equations or Monster Matrices and How to Care for Them
  abstract: We look at Krylov methods for solving large systems of linear equations. Convergence theory will be given in a hopefully easy way to understand, at least for people who like surfing. Then deflating eigenvalues is mentioned, and deflation is used in a two-grid BiCGStab method. Also, a new stable polynomial preconditioning approach will be given. Next, Krylov methods are developed for rank-one updated systems and maybe there will be time to apply this to singular matrices. Bears will be mentioned along the way including a certain English bear named Winnie. However, no animals will be harmed by this talk except for the feelings of a certain giraffe. 

- date: 19 Feb 2021
  speaker: Leon Bungert (Erlangen, Germany)
  url: https://sites.google.com/view/leon-bungert
  teams: https://teams.microsoft.com/l/meetup-join/19%3ad8aa162230c14a67a10243ac2f75d98d%40thread.tacv2/1612172995109?context=%7b%22Tid%22%3a%22377e3d22-4ea1-422d-b0ad-8fcc89406b9e%22%2c%22Oid%22%3a%22ca31603c-bea1-49a9-9542-de84a57ad77c%22%7d
  title: 	Continuum Limit for Lipschitz Learning on Graphs
  abstract: "In semi-supervised learning one is confronted with a large set of data points, only very few of which are labelled. The task is to find a labelling function which extends these labels to the whole data set. In order to find useful labelling functions, in graph-based semi-supervised learning one represents the data set as weighted graph and poses a smoothness constraint on the labelling function. In this context p-Laplacian learning has become very popular and consists in finding a p-harmonic function which coincides with labels on the labelled set. However, this method is asymptotically ill-posed if p is smaller than the dimension of the data space, and is not feasible for most applications. 
  
  In this work, I will therefore speak about Lipschitz-learning which aims to find a Lipschitz-extension of the labels and is well-posed in arbitrary dimension. The main result is a discrete-to-continuum limit of Lipschitz-extensions as the data set grows to a continuum. Our theory uses Gamma-convergence and Hausdorff convergence of the data set. As a by-product we obtain a continuum limit for a nonlinear eigenvalue problem related to geodesic distance functions."
  
- date: 26 Feb 2021
  speaker: Rob Scheichl (Heidelberg, Germany)
  url: https://ganymed.math.uni-heidelberg.de/~rscheichl/
  teams: https://teams.microsoft.com/l/meetup-join/19%3ad8aa162230c14a67a10243ac2f75d98d%40thread.tacv2/1612172995109?context=%7b%22Tid%22%3a%22377e3d22-4ea1-422d-b0ad-8fcc89406b9e%22%2c%22Oid%22%3a%22ca31603c-bea1-49a9-9542-de84a57ad77c%22%7d
  title: Optimal local approximation spaces for generalized finite element methods
  abstract: In this talk, I present new optimal local approximation spaces for the generalized finite element method for solving second order elliptic equations with rough coefficients, which are based on local eigenvalue problems involving the partition of unity. In addition to a nearly exponential decay rate of the local approximation error with respect to the dimension of the local spaces, I also give the rate of convergence with respect to the size of the oversampling region. To reduce the computational cost of the method, an efficient and easy-to-implement technique for generating the necessary discrete A-harmonic spaces is proposed. Numerical experiments are presented to support the theoretical analysis and confirm the effectiveness of the method. This is joint work with Chupeng Ma (Heidelberg).
  
- date: 5 Mar 2021
  speaker: Dante Kalise (Nottingham)
  url: https://sites.google.com/view/dkalise
  teams: https://teams.microsoft.com/l/meetup-join/19%3ad8aa162230c14a67a10243ac2f75d98d%40thread.tacv2/1612172995109?context=%7b%22Tid%22%3a%22377e3d22-4ea1-422d-b0ad-8fcc89406b9e%22%2c%22Oid%22%3a%22ca31603c-bea1-49a9-9542-de84a57ad77c%22%7d
  title: Synthetic data-driven methods for approximating high-dimensional Hamilton-Jacobi PDEs
  abstract: "Hamilton-Jacobi PDEs are central in control and differential games, enabling the computation of optimal control laws expressed in feedback form. High-dimensional HJ PDEs naturally arise in the feedback synthesis for high-dimensional control systems, and their numerical solution must be sought outside the framework provided by standard grid-based discretizations methods. 
  In this talk, I will discuss the construction of causality-free, data-driven methods for the approximation of high-dimensional HJ PDEs. I will address the generation of a synthetic dataset based on the use of representation formulas (such as Lax-Hopf or Pontryagin's Maximum Principle), which is then fed into a high-dimensional sparse polynomial/ANN model for training. The use of representation formulas providing gradient information is fundamental to increase the data efficiency of the method. I will present applications in nonlinear dynamics, control of PDEs, and agent-based models."

- date: 12 Mar 2021
  speaker: Eike Mueller (Bath)
  url: https://people.bath.ac.uk/em459/
  teams: https://teams.microsoft.com/l/meetup-join/19%3ad8aa162230c14a67a10243ac2f75d98d%40thread.tacv2/1612172995109?context=%7b%22Tid%22%3a%22377e3d22-4ea1-422d-b0ad-8fcc89406b9e%22%2c%22Oid%22%3a%22ca31603c-bea1-49a9-9542-de84a57ad77c%22%7d
  title: 	'TBC'
  abstract: 'TBC'
  
- date: 19 Mar 2021
  speaker: Milvia Rossini (Bicocca, Milano, Italy)
  url: https://en.unimib.it/milvia-francesca-rossini
  teams: https://teams.microsoft.com/l/meetup-join/19%3ad8aa162230c14a67a10243ac2f75d98d%40thread.tacv2/1612172995109?context=%7b%22Tid%22%3a%22377e3d22-4ea1-422d-b0ad-8fcc89406b9e%22%2c%22Oid%22%3a%22ca31603c-bea1-49a9-9542-de84a57ad77c%22%7d
  title: 	'TBC'
  abstract: 'TBC'
  
- date: 26 Mar 2021
  speaker: Tiangang Cui (Monash University, Australia)
  url: https://www.fastfins.org/
  teams: https://teams.microsoft.com/l/meetup-join/19%3ad8aa162230c14a67a10243ac2f75d98d%40thread.tacv2/1612172995109?context=%7b%22Tid%22%3a%22377e3d22-4ea1-422d-b0ad-8fcc89406b9e%22%2c%22Oid%22%3a%22ca31603c-bea1-49a9-9542-de84a57ad77c%22%7d
  title: 	'TBC'
  abstract: 'TBC'
  
- date: 16 Apr 2021
  speaker: James Foster (Oxford)
  url: https://www.maths.ox.ac.uk/people/james.foster
  teams: https://teams.microsoft.com/l/meetup-join/19%3ad8aa162230c14a67a10243ac2f75d98d%40thread.tacv2/1612172995109?context=%7b%22Tid%22%3a%22377e3d22-4ea1-422d-b0ad-8fcc89406b9e%22%2c%22Oid%22%3a%22ca31603c-bea1-49a9-9542-de84a57ad77c%22%7d
  title: 	'TBC'
  abstract: 'TBC'
  
- date: 23 Apr 2021
  speaker: Sergey Dolgov (Bath)
  url: https://people.bath.ac.uk/sd901/
  teams: https://teams.microsoft.com/l/meetup-join/19%3ad8aa162230c14a67a10243ac2f75d98d%40thread.tacv2/1612172995109?context=%7b%22Tid%22%3a%22377e3d22-4ea1-422d-b0ad-8fcc89406b9e%22%2c%22Oid%22%3a%22ca31603c-bea1-49a9-9542-de84a57ad77c%22%7d
  title: 	'TBC'
  abstract: 'TBC'
  
- date: 30 Apr 2021
  speaker: Yuya Suzuki (NTNU, Norway)
  url: https://www.ntnu.edu/employees/yuya.suzuki
  teams: https://teams.microsoft.com/l/meetup-join/19%3ad8aa162230c14a67a10243ac2f75d98d%40thread.tacv2/1612172995109?context=%7b%22Tid%22%3a%22377e3d22-4ea1-422d-b0ad-8fcc89406b9e%22%2c%22Oid%22%3a%22ca31603c-bea1-49a9-9542-de84a57ad77c%22%7d
  title: 	'TBC'
  abstract: 'TBC'
  
- date: 7 May 2021
  speaker: Jarrod Williams (Bath)
  url: https://researchportal.bath.ac.uk/en/persons/jarrod-williams
  teams: https://teams.microsoft.com/l/meetup-join/19%3ad8aa162230c14a67a10243ac2f75d98d%40thread.tacv2/1612172995109?context=%7b%22Tid%22%3a%22377e3d22-4ea1-422d-b0ad-8fcc89406b9e%22%2c%22Oid%22%3a%22ca31603c-bea1-49a9-9542-de84a57ad77c%22%7d
  title: 	'TBC'
  abstract: 'TBC'
